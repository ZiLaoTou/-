{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM的Pytorch API使用以及手动实现LSTM Forward函数\n",
    "- [LSTM的理解｜博客](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "- 这里实现了LSTM和LSTMP，其中LSTMP就是对隐藏状态和输出的维度进行了压缩，可以降低计算量和参数量\n",
    "- 这里只实现了单向、单层的LSTM，双向或者双层的情况和RNN是类似的\n",
    "- LSTM Forward公式：\n",
    "    - ![lstm_froward](<https://github.com/ZiLaoTou/Study/blob/main/models/pictures/lstm_froward.png?raw=ture>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "bs, T, i_size, h_size = 2, 3, 4, 5  # 批大小, 输入序列长度, 输入特征长度, 输出特征长度\n",
    "proj_size = 3 # 一般proj_size比h_size小，进行压缩\n",
    "input = torch.randn(bs, T, i_size)  # 随机初始化一个特征序列\n",
    "h0 = torch.zeros(bs, h_size)  # 初始隐含状态\n",
    "c0 = torch.zeros(bs, h_size)  # 初始值 不会参与训练 初始细胞状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0714,  0.0557, -0.2320, -0.0338, -0.0112],\n",
      "         [ 0.1384, -0.0942, -0.1996,  0.0266, -0.1163],\n",
      "         [-0.0767, -0.0132, -0.2811, -0.0877, -0.0204]],\n",
      "\n",
      "        [[-0.1511,  0.1231,  0.1563, -0.1965,  0.1836],\n",
      "         [-0.1608,  0.2854, -0.0331, -0.1999,  0.1192],\n",
      "         [-0.1810,  0.2089, -0.1762, -0.0931,  0.0287]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "weight_ih_l0 torch.Size([20, 4])\n",
      "weight_hh_l0 torch.Size([20, 5])\n",
      "bias_ih_l0 torch.Size([20])\n",
      "bias_hh_l0 torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# LSTM的Pytorch官方API调用\n",
    "lstm_layer = nn.LSTM(i_size, h_size, batch_first = True)\n",
    "output, (h_final, c_final) = lstm_layer(input, (h0.unsqueeze(0), c0.unsqueeze(0)))\n",
    "print(output)\n",
    "\n",
    "for k, v in lstm_layer.named_parameters():\n",
    "    print(k, v.shape)\n",
    "# 这里注意一下，虽然LSTM分为cell门、遗忘门、输入门、输出门等等，但是在内部实现的时候是会把他们的参数concat起来(在第0维, 5*4）一起进行快速矩阵运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM的动手实现\n",
    "def lstm_forward(input, initial_states: tuple, w_ih, w_hh, b_ih, b_hh):\n",
    "    h0, c0 = initial_states # 初始隐含状态和初始细胞状态\n",
    "    bs, T, i_size = input.shape\n",
    "    h_size = w_ih.shape[0] // 4\n",
    "    # 注意这里不能是 w_hh.shape[1] 这样的话如果没有proj就还好  有proj的时候这个值就等于proj_size了  而不是h_size\n",
    "    prev_h = h0\n",
    "    prev_c = c0\n",
    "    \n",
    "    output_size = h_size\n",
    "    output = torch.zeros(bs, T, output_size)\n",
    "    \n",
    "    for t in range(T):\n",
    "        x = input[:, t, :] # [bs, i_size]\n",
    "        w_times_x = x @ w_ih.T # [bs, h_size*4]\n",
    "        w_times_h = prev_h @ w_hh.T # [bs, h_size*4]\n",
    "\n",
    "        # 分别计算输入门i  遗忘门f  cell门g  输出门o\n",
    "        i_t = torch.sigmoid(w_times_x[:, :h_size] + w_times_h[:, :h_size] + b_ih[:h_size] + b_hh[:h_size])\n",
    "        f_t = torch.sigmoid(w_times_x[:, h_size:2*h_size] + w_times_h[:, h_size:2*h_size] + b_ih[h_size:2*h_size] + b_hh[h_size:2*h_size])\n",
    "        g_t = torch.tanh(w_times_x[:, 2*h_size:3*h_size] + w_times_h[:, 2*h_size:3*h_size] + b_ih[2*h_size:3*h_size] + b_hh[2*h_size:3*h_size])\n",
    "        o_t = torch.sigmoid(w_times_x[:, 3*h_size:] + w_times_h[:, 3*h_size:] + b_ih[3*h_size:] + b_hh[3*h_size:])\n",
    "\n",
    "        prev_c = f_t * prev_c + i_t * g_t\n",
    "        prev_h = o_t * torch.tanh(prev_c)\n",
    "\n",
    "        output[:, t, :] = prev_h\n",
    "\n",
    "    return output, (prev_h, prev_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证\n",
    "output_custom, (h_final_custom, c_final_custom) = lstm_forward(input, (h0, c0), lstm_layer.weight_ih_l0, lstm_layer.weight_hh_l0, \\\n",
    "                                                               lstm_layer.bias_ih_l0, lstm_layer.bias_hh_l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch API output:\n",
      "tensor([[[ 0.0714,  0.0557, -0.2320, -0.0338, -0.0112],\n",
      "         [ 0.1384, -0.0942, -0.1996,  0.0266, -0.1163],\n",
      "         [-0.0767, -0.0132, -0.2811, -0.0877, -0.0204]],\n",
      "\n",
      "        [[-0.1511,  0.1231,  0.1563, -0.1965,  0.1836],\n",
      "         [-0.1608,  0.2854, -0.0331, -0.1999,  0.1192],\n",
      "         [-0.1810,  0.2089, -0.1762, -0.0931,  0.0287]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.0767, -0.0132, -0.2811, -0.0877, -0.0204],\n",
      "         [-0.1810,  0.2089, -0.1762, -0.0931,  0.0287]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.2929, -0.0275, -0.4630, -0.2035, -0.0659],\n",
      "         [-0.4735,  0.4182, -0.3645, -0.1707,  0.0601]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "\n",
      "lstm_forward function output:\n",
      "tensor([[[ 0.0714,  0.0557, -0.2320, -0.0338, -0.0112],\n",
      "         [ 0.1384, -0.0942, -0.1996,  0.0266, -0.1163],\n",
      "         [-0.0767, -0.0132, -0.2811, -0.0877, -0.0204]],\n",
      "\n",
      "        [[-0.1511,  0.1231,  0.1563, -0.1965,  0.1836],\n",
      "         [-0.1608,  0.2854, -0.0331, -0.1999,  0.1192],\n",
      "         [-0.1810,  0.2089, -0.1762, -0.0931,  0.0287]]], grad_fn=<CopySlices>)\n",
      "tensor([[-0.0767, -0.0132, -0.2811, -0.0877, -0.0204],\n",
      "        [-0.1810,  0.2089, -0.1762, -0.0931,  0.0287]], grad_fn=<MulBackward0>)\n",
      "tensor([[-0.2929, -0.0275, -0.4630, -0.2035, -0.0659],\n",
      "        [-0.4735,  0.4182, -0.3645, -0.1707,  0.0601]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch API output:\")\n",
    "print(output)\n",
    "print(h_final) \n",
    "print(c_final)\n",
    "print(\"\\nlstm_forward function output:\")\n",
    "print(output_custom) \n",
    "print(h_final_custom)\n",
    "print(c_final_custom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0128, -0.0518, -0.1154],\n",
      "         [ 0.0257, -0.0022, -0.1165],\n",
      "         [ 0.0881, -0.0497, -0.0371]],\n",
      "\n",
      "        [[-0.0928,  0.0179,  0.0172],\n",
      "         [-0.0733, -0.0163, -0.0497],\n",
      "         [ 0.0461, -0.0044, -0.0177]]], grad_fn=<TransposeBackward0>)\n",
      "weight_ih_l0 torch.Size([20, 4])\n",
      "weight_hh_l0 torch.Size([20, 3])\n",
      "bias_ih_l0 torch.Size([20])\n",
      "bias_hh_l0 torch.Size([20])\n",
      "weight_hr_l0 torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "# 接下来使用proj_size参数\n",
    "# 使用了proj_size的官方实现\n",
    "lstm_layer_proj = nn.LSTM(i_size, h_size, batch_first = True, proj_size=proj_size)\n",
    "# 当使用proj的时候，会对h维度进行压缩，所以相应的输入需要改变\n",
    "h0_proj = torch.randn(bs, proj_size)\n",
    "output_proj, (h_final_proj, c_final_proj) = lstm_layer_proj(input, (h0_proj.unsqueeze(0), c0.unsqueeze(0)))\n",
    "print(output_proj)\n",
    "\n",
    "for k, v in lstm_layer_proj.named_parameters():\n",
    "    print(k, v.shape) \n",
    "# 可以看到多了一个参数weight_hr_l0, 这个参数就是用来对隐藏层特征维度进行压缩的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用了proj_size的手动实现\n",
    "def lstm_forward_proj(input, initial_states: tuple, w_ih, w_hh, b_ih, b_hh, w_hr=None):\n",
    "    h0, c0 = initial_states # 初始隐含状态和初始细胞状态\n",
    "    bs, T, i_size = input.shape\n",
    "    h_size = w_ih.shape[0] // 4\n",
    "    # 注意这里不能是 w_hh.shape[1] 这样的话如果没有proj就还好  有proj的时候这个值就等于proj_size了  而不是h_size\n",
    "\n",
    "    prev_h = h0\n",
    "    prev_c = c0\n",
    "\n",
    "    # 有了proj以后, ouput的大小会发生改变\n",
    "    if w_hr is not None:\n",
    "        p_size = w_hr.shape[0]\n",
    "        output_size = p_size\n",
    "    else:\n",
    "        output_size = h_size\n",
    "    output = torch.zeros(bs, T, output_size)\n",
    "    \n",
    "    for t in range(T):\n",
    "        x = input[:, t, :] # [bs, i_size]\n",
    "        w_times_x = x @ w_ih.T # [bs, h_size*4]\n",
    "        w_times_h = prev_h @ w_hh.T # [bs, h_size*4]\n",
    "\n",
    "        # 分别计算输入门i  遗忘门f  cell门g  输出门o\n",
    "        i_t = torch.sigmoid(w_times_x[:, :h_size] + w_times_h[:, :h_size] + b_ih[:h_size] + b_hh[:h_size])\n",
    "        f_t = torch.sigmoid(w_times_x[:, h_size:2*h_size] + w_times_h[:, h_size:2*h_size] + b_ih[h_size:2*h_size] + b_hh[h_size:2*h_size])\n",
    "        g_t = torch.tanh(w_times_x[:, 2*h_size:3*h_size] + w_times_h[:, 2*h_size:3*h_size] + b_ih[2*h_size:3*h_size] + b_hh[2*h_size:3*h_size])\n",
    "        o_t = torch.sigmoid(w_times_x[:, 3*h_size:] + w_times_h[:, 3*h_size:] + b_ih[3*h_size:] + b_hh[3*h_size:])\n",
    "\n",
    "        prev_c = f_t * prev_c + i_t * g_t\n",
    "        prev_h = o_t * torch.tanh(prev_c) # [bs, h_size]\n",
    "        \n",
    "        if w_hr is not None:\n",
    "            prev_h = prev_h @ w_hr.T # [bs, p_size]\n",
    "\n",
    "        output[:, t, :] = prev_h # [bs, p_size]\n",
    "\n",
    "    return output, (prev_h, prev_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证\n",
    "output_custom_proj, (h_final_custom_proj, c_final_custom_proj) = lstm_forward_proj(input, (h0_proj, c0), lstm_layer_proj.weight_ih_l0, lstm_layer_proj.weight_hh_l0, \\\n",
    "                                                               lstm_layer_proj.bias_ih_l0, lstm_layer_proj.bias_hh_l0, lstm_layer_proj.weight_hr_l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch API output:\n",
      "tensor([[[-0.0128, -0.0518, -0.1154],\n",
      "         [ 0.0257, -0.0022, -0.1165],\n",
      "         [ 0.0881, -0.0497, -0.0371]],\n",
      "\n",
      "        [[-0.0928,  0.0179,  0.0172],\n",
      "         [-0.0733, -0.0163, -0.0497],\n",
      "         [ 0.0461, -0.0044, -0.0177]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.0881, -0.0497, -0.0371],\n",
      "         [ 0.0461, -0.0044, -0.0177]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.3565, -0.0455,  0.1897,  0.0373,  0.1310],\n",
      "         [-0.0269, -0.0201,  0.5269, -0.1776,  0.0187]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "\n",
      "lstm_forward function output:\n",
      "tensor([[[-0.0128, -0.0518, -0.1154],\n",
      "         [ 0.0257, -0.0022, -0.1165],\n",
      "         [ 0.0881, -0.0497, -0.0371]],\n",
      "\n",
      "        [[-0.0928,  0.0179,  0.0172],\n",
      "         [-0.0733, -0.0163, -0.0497],\n",
      "         [ 0.0461, -0.0044, -0.0177]]], grad_fn=<CopySlices>)\n",
      "tensor([[ 0.0881, -0.0497, -0.0371],\n",
      "        [ 0.0461, -0.0044, -0.0177]], grad_fn=<MmBackward0>)\n",
      "tensor([[-0.3565, -0.0455,  0.1897,  0.0373,  0.1310],\n",
      "        [-0.0269, -0.0201,  0.5269, -0.1776,  0.0187]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch API output:\")\n",
    "print(output_proj)\n",
    "print(h_final_proj) \n",
    "print(c_final_proj)\n",
    "print(\"\\nlstm_forward function output:\")\n",
    "print(output_custom_proj) \n",
    "print(h_final_custom_proj)\n",
    "print(c_final_custom_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
