{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU的Pytorch API使用以及手动实现GRU Forward函数\n",
    "- GRU Forward公式：\n",
    "    - 从公式可以看出，单层GRU网络的参数约等于单层LSTM参数的0.75倍\n",
    "    - ![gru_forward](<https://github.com/ZiLaoTou/Study/blob/main/models/pictures/gru_forward.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "bs, T, i_size, h_size = 2, 3, 4, 5  # 批大小, 输入序列长度, 输入特征长度, 输出特征长度\n",
    "input = torch.randn(bs, T, i_size)  # 随机初始化一个特征序列\n",
    "h0 = torch.zeros(bs, h_size)  # 初始隐含状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Forward的动手实现\n",
    "def gru_forward(input, initial_state, w_ih, w_hh, b_ih, b_hh):\n",
    "    prev_h = initial_state\n",
    "    bs, T, i_size = input.shape\n",
    "    h_size = w_ih.shape[0] // 3\n",
    "\n",
    "    output = torch.zeros(bs, T, h_size)  # 输出  如果是动手实现GRU类  这个应该放在类初始化中初始化为属性\n",
    "    \n",
    "    for t in range(T):\n",
    "        x = input[:, t, :]\n",
    "        w_times_x = x @ w_ih.T           # [bs, 3*h_size]\n",
    "        w_times_h = prev_h @ w_hh.T      # [bs, 3* h_size]\n",
    "\n",
    "        # 重置门r_t\n",
    "        r_t = torch.sigmoid(w_times_x[:, :h_size] + w_times_h[:, :h_size] + b_ih[:h_size] + b_hh[:h_size])\n",
    "        # 更新门\n",
    "        z_t = torch.sigmoid(w_times_x[:, h_size:2*h_size] + w_times_h[:, h_size:2*h_size] + \\\n",
    "                                                            b_ih[h_size:2*h_size] + b_hh[h_size:2*h_size])\n",
    "        # 候选状态\n",
    "        n_t = torch.tanh(w_times_x[:,2*h_size:3*h_size] + b_ih[2*h_size:3*h_size] + \\\n",
    "                                                            r_t * (w_times_h[:, 2*h_size:3*h_size] + b_hh[2*h_size:3*h_size]))\n",
    "        prev_h = (1 - z_t) * n_t + z_t * prev_h\n",
    "\n",
    "        output[:, t, :] = prev_h\n",
    "    \n",
    "    return output, prev_h\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([15, 4])\n",
      "weight_hh_l0 torch.Size([15, 5])\n",
      "bias_ih_l0 torch.Size([15])\n",
      "bias_hh_l0 torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "# Pytorch API\n",
    "gru_layer = nn.GRU(i_size, h_size, batch_first = True)\n",
    "output, h_final = gru_layer(input, h0.unsqueeze(0))\n",
    "\n",
    "\n",
    "for k, v in gru_layer.named_parameters():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "output_custom, h_final_custom  = gru_forward(input, h0, gru_layer.weight_ih_l0, gru_layer.weight_hh_l0, gru_layer.bias_ih_l0, gru_layer.bias_hh_l0)\n",
    "\n",
    "print(torch.allclose(output, output_custom))\n",
    "print(torch.allclose(h_final, h_final_custom))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
